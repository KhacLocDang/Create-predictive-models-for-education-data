{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import f1_score,accuracy_score,classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "from imblearn.combine import SMOTETomek\n",
    "from collections import Counter\n",
    "# import statistics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Đọc, chia dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Final= pd.read_csv('df_nhanh13141516.csv')\n",
    "df_Final = df_Final.iloc[: , 1:]\n",
    "df_Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "df_train, df_val = train_test_split(df_Final, test_size=0.25,shuffle=True ,random_state=seed,stratify=df_Final[\"nhan_xuhuong\"])\n",
    "X_train = df_train.copy()\n",
    "y_train = X_train.pop(\"nhan_xuhuong\")\n",
    "print(y_train.value_counts())\n",
    "X_val = df_val.copy()\n",
    "y_val = X_val.pop(\"nhan_xuhuong\")\n",
    "print(y_val.value_counts())\n",
    "# le=preprocessing.LabelBinarizer() --ko cân bằng trực tiếp được và cho kết quả thấp hơn LabelEncoder()\n",
    "le = preprocessing.LabelEncoder()\n",
    "le=le.fit(y_train)\n",
    "\n",
    "y_train =le.transform(y_train)\n",
    "y_val=le.transform(y_val)\n",
    "print(y_train)\n",
    "print(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tiền xử lý và mã hóa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Somon_canlay=19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHotEncoder để mặc định ma trận thưa thớt sparse=true giúp giảm kích thước bộ nhớ\n",
    "cat_cols = []\n",
    "\n",
    "cat_cols.extend(['gioitinh','noisinh','cmnd_noicap'\n",
    "                  ,'lopsh','khoa','hedt_sv','chuyennganh','chuyennganh2','nganh_tt','dantoc','tongiao',\n",
    "                 'xuatthan','doituong','khuvuc'])\n",
    "for i in range(Somon_canlay):\n",
    "    mamh_='mamh_'+str(i+1)\n",
    "    trangthaimon_='trangthaimon_'+str(i+1)\n",
    "    hinhthucthmon_='hinhthucthmon_'+str(i+1)\n",
    "    ngonngumon_='ngonngumon_'+str(i+1)\n",
    "    khoaqlmon_='khoaqlmon_'+str(i+1)\n",
    "    hedt_monhoc_='hedt_monhoc_'+str(i+1)\n",
    "    hocky_mon_='hocky_mon_'+str(i+1)\n",
    "    cat_cols.extend([mamh_,trangthaimon_,\n",
    "                        hinhthucthmon_,ngonngumon_,\n",
    "                        khoaqlmon_,hedt_monhoc_,hocky_mon_])\n",
    "\n",
    "# cat_cols.extend(['loaihocluc_hk1','loaihocluc_hk2','diff_loaihocluc_hk'\n",
    "#                  ,'loaihoclucnam'])\n",
    "\n",
    "cat_cols= np.array(cat_cols)\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = []\n",
    "\n",
    "num_cols.extend(['tuoivaodh','tuoicapcmnd'])\n",
    "for i in range(Somon_canlay):\n",
    "    diemmon_='diemmon_'+str(i+1)\n",
    "\n",
    "    num_cols.extend([diemmon_])\n",
    "\n",
    "num_cols.extend(['dtb_hk1','sotc_hk1','dtb_hk2','sotc_hk2',\n",
    "                    'tong_sotc','dtbnam'])\n",
    "    \n",
    "\n",
    "num_cols= np.array(num_cols)\n",
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_transformer = Pipeline(\n",
    "    steps=[(\"scaler\", StandardScaler())]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", num_transformer, num_cols),\n",
    "        (\"cat\", cat_transformer, cat_cols),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#out put là numpy array\n",
    "X_train=preprocessor.fit_transform(X_train, y_train)\n",
    "X_val=preprocessor.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "dump(preprocessor, \"preprocessor_Final_huong13_Randomforest.dat\")\n",
    "print(\"Saved model to: preprocessor_Final_huong13_Randomforest.dat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CB dữ liệu: Cb dữ liệu huấn luyện, KO cb dữ liệu test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "smote_tomek = SMOTETomek(random_state=seed)\n",
    "\n",
    "X_train, y_train = smote_tomek.fit_resample(X_train,y_train)\n",
    "\n",
    "print(sorted(Counter(y_train).items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_DT=DecisionTreeClassifier(random_state=seed)\n",
    "\n",
    "# training\n",
    "model_DT.fit(X_train, y_train)\n",
    "\n",
    "# training metric\n",
    "y_train_pred_DT = model_DT.predict(X_train)\n",
    "print(f\"Accuracy score on train data: {accuracy_score(list(y_train), list(y_train_pred_DT)):.2f}\")\n",
    "\n",
    "# validation metric\n",
    "y_pred_DT = model_DT.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_val, y_pred_DT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#min_impurity_decrease ngưỡng ngừng phát triển, dừng sớm để đỡ bọ overfiting\n",
    "model_RF=RandomForestClassifier(random_state=seed)\n",
    "\n",
    "# training\n",
    "model_RF.fit(X_train, y_train)\n",
    "\n",
    "# training metric\n",
    "y_train_pred_RF = model_RF.predict(X_train)\n",
    "print(f\"Accuracy score on train data: {accuracy_score(list(y_train), list(y_train_pred_RF)):.2f}\")\n",
    "\n",
    "# validation metric\n",
    "y_pred_RF = model_RF.predict(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_val, y_pred_RF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy score on validation data: {accuracy_score(list(y_val), list(y_pred_RF))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_val, y_pred_RF,average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_val, y_pred_RF, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_val, y_pred_RF, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_XGB=xgb.XGBClassifier(random_state=seed)\n",
    "\n",
    "# training\n",
    "model_XGB.fit(X_train, y_train)\n",
    "\n",
    "# training metric\n",
    "y_train_pred_XGB = model_XGB.predict(X_train)\n",
    "print(f\"Accuracy score on train data: {accuracy_score(list(y_train), list(y_train_pred_XGB)):.2f}\")\n",
    "\n",
    "# validation metric\n",
    "y_pred_XGB = model_XGB.predict(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_val, y_pred_XGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feartures selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model using each importance as a threshold\n",
    "thresholds = np.sort(model_RF.feature_importances_)\n",
    "# thresholds =thresholds.tolist()\n",
    "# mean=statistics.mean(thresholds)\n",
    "# thresholds = [t for t in thresholds if t >= mean]\n",
    "# thresholds=sorted(set(thresholds))\n",
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonzero_thresholds= thresholds[np.nonzero(thresholds)]\n",
    "nonzero_thresholds=np.sort(nonzero_thresholds)\n",
    "nonzero_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonzero_thresholds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# select features using threshold\n",
    "selection = SelectFromModel(model_RF, threshold=nonzero_thresholds[0], prefit=True)\n",
    "select_X_train = selection.transform(X_train)\n",
    "\n",
    "# train model\n",
    "selection_model = RandomForestClassifier(random_state=seed)\n",
    "selection_model.fit(select_X_train, y_train)\n",
    "\n",
    "# eval model\n",
    "select_X_val = selection.transform(X_val)\n",
    "select_y_pred = selection_model.predict(select_X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_val, select_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(model_RF, \"M_Final_huong13_Randomforest.dat\")\n",
    "print(\"Saved model to: M_Final_huong13_Randomforest.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RandomOverSample\n",
    "# ros = RandomOverSampler(random_state=seed)\n",
    "\n",
    "# X_train, y_train = ros.fit_resample(X_train,y_train)\n",
    "\n",
    "# print(sorted(Counter(y_train).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RandomUnderSampler\n",
    "# rus = RandomUnderSampler(random_state=seed)\n",
    "\n",
    "# X_train, y_train = rus.fit_resample(X_train,y_train)\n",
    "\n",
    "# print(sorted(Counter(y_train).items()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svmsmote = SVMSMOTE(random_state=seed)\n",
    "\n",
    "# X_train, y_train = svmsmote.fit_resample(X_train,y_train)\n",
    "\n",
    "# print(sorted(Counter(y_train).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# blsmote = BorderlineSMOTE(random_state=seed)\n",
    "\n",
    "# X_train, y_train = blsmote.fit_resample(X_train,y_train)\n",
    "\n",
    "# print(sorted(Counter(y_train).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # smote phải là số đã\n",
    "# smote = SMOTE(random_state=seed)\n",
    "\n",
    "# X_train, y_train = smote.fit_resample(X_train,y_train)\n",
    "\n",
    "# print(sorted(Counter(y_train).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# kmsmote = KMeansSMOTE(random_state=seed)\n",
    "\n",
    "# X_train, y_train = kmsmote.fit_resample(X_train,y_train)\n",
    "\n",
    "# print(sorted(Counter(y_train).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# adasyn = ADASYN(random_state=seed)\n",
    "\n",
    "# X_train, y_train = adasyn.fit_resample(X_train,y_train)\n",
    "\n",
    "# print(sorted(Counter(y_train).items()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# cc = ClusterCentroids(random_state=seed)\n",
    "\n",
    "# X_train, y_train = cc.fit_resample(X_train,y_train)\n",
    "\n",
    "# print(sorted(Counter(y_train).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# smote_enn = SMOTEENN(random_state=seed)\n",
    "\n",
    "# X_train, y_train = smote_enn.fit_resample(X_train,y_train)\n",
    "\n",
    "# print(sorted(Counter(y_train).items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thuật toán có khả năng cân bằng trước khi mã hóa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical_var = np.where(X_train.dtypes != np.float)[0]\n",
    "# # smote phải là số đã\n",
    "# smotenc = SMOTENC(categorical_var,random_state=seed)\n",
    "\n",
    "# X_train, y_train = smotenc.fit_resample(X_train,y_train)\n",
    "\n",
    "# print(sorted(Counter(y_train).items()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
